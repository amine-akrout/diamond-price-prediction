{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to your workspace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create conda environment from yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env create -f myenv.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Workspace\n",
    "Initialize a workspace object from json configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.36.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"Ready to use Azure ML\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure_ml loaded\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, \"loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and register the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml_globaldatasets - Default = False\n",
      "workspaceworkingdirectory - Default = False\n",
      "workspaceblobstore - Default = True\n",
      "workspaceartifactstore - Default = False\n",
      "workspacefilestore - Default = False\n"
     ]
    }
   ],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ds.upload_files(files=['./data/diamonds.csv'],\n",
    "                       target_path='diamond-data/', \n",
    "                       overwrite=True,\n",
    "                       show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1  carat      cut color clarity  depth  table  price     x     y  \\\n",
       "0        1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
       "1        2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
       "2        3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07   \n",
       "3        4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23   \n",
       "4        5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35   \n",
       "\n",
       "      z  \n",
       "0  2.43  \n",
       "1  2.31  \n",
       "2  2.31  \n",
       "3  2.63  \n",
       "4  2.75  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diamond-data/*.csv'))\n",
    "\n",
    "# Display the first 5 rows as a Pandas dataframe\n",
    "tab_data_set.take(5).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the tabular dataset\n",
    "try:\n",
    "    tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                        name='diamond dataset',\n",
    "                                        description='diamond data',\n",
    "                                        tags = {'format':'CSV'},\n",
    "                                        create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    \n",
    "print('Datasets registered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting conda specifications for existing conda environment: az_env\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "tf_env = Environment.from_existing_conda_environment(name=\"tf_env\", conda_environment_name=\"az_env\")\n",
    "tf_env.save_to_directory(path=\"./tf_env\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'dimond_experiment'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dabdeb25cf749ea984311775eb0fb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/dimond_experiment_1639396756_a9e45179?wsid=/subscriptions/476494f9-6d6e-4cb0-87aa-0e2af17a1cf0/resourcegroups/ml/workspaces/azure_ml&tid=164ae192-78d8-4cdf-97f3-9b8996479a42\", \"run_id\": \"dimond_experiment_1639396756_a9e45179\", \"run_properties\": {\"run_id\": \"dimond_experiment_1639396756_a9e45179\", \"created_utc\": \"2021-12-13T11:59:17.86411Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"afa937ca-63a3-46c2-83ec-cbb6934d65d3\", \"azureml.git.repository_uri\": \"https://github.com/amine-akrout/diamond-price-prediction.git\", \"mlflow.source.git.repoURL\": \"https://github.com/amine-akrout/diamond-price-prediction.git\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"e8a632cb9fe5b8164a4a9bb64efe284b2ee98641\", \"mlflow.source.git.commit\": \"e8a632cb9fe5b8164a4a9bb64efe284b2ee98641\", \"azureml.git.dirty\": \"False\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-12-13T12:08:46.277592Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://azureml5251422572.blob.core.windows.net/azureml/ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=ps%2FBJhPw3PnUny0husVNdZvIi6BepMT19H74QFvfo1s%3D&skoid=33ba0eac-bf3e-4596-b8a9-4b07563781ca&sktid=164ae192-78d8-4cdf-97f3-9b8996479a42&skt=2021-12-13T11%3A58%3A20Z&ske=2021-12-14T20%3A08%3A20Z&sks=b&skv=2019-07-07&st=2021-12-13T15%3A59%3A43Z&se=2021-12-14T00%3A09%3A43Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://azureml5251422572.blob.core.windows.net/azureml/ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=fnuB5n74j%2FE8%2B2zvmDUbAP8He22PU0bNUD5ww3SgkTw%3D&skoid=33ba0eac-bf3e-4596-b8a9-4b07563781ca&sktid=164ae192-78d8-4cdf-97f3-9b8996479a42&skt=2021-12-13T11%3A58%3A20Z&ske=2021-12-14T20%3A08%3A20Z&sks=b&skv=2019-07-07&st=2021-12-13T15%3A59%3A43Z&se=2021-12-14T00%3A09%3A43Z&sp=r\", \"logs/azureml/16172_azureml.log\": \"https://azureml5251422572.blob.core.windows.net/azureml/ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/logs/azureml/16172_azureml.log?sv=2019-07-07&sr=b&sig=KH%2Bw%2BJ1XMW70oVJ6cubRtMHMOpfaS3AcPbn40aU%2FpWk%3D&skoid=33ba0eac-bf3e-4596-b8a9-4b07563781ca&sktid=164ae192-78d8-4cdf-97f3-9b8996479a42&skt=2021-12-13T15%3A37%3A36Z&ske=2021-12-14T23%3A47%3A36Z&sks=b&skv=2019-07-07&st=2021-12-13T16%3A03%3A12Z&se=2021-12-14T00%3A13%3A12Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://azureml5251422572.blob.core.windows.net/azureml/ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=LAVFrEJH0E7INHItW575vkjodBEtjfyYT9CgFstWi9U%3D&skoid=33ba0eac-bf3e-4596-b8a9-4b07563781ca&sktid=164ae192-78d8-4cdf-97f3-9b8996479a42&skt=2021-12-13T15%3A37%3A36Z&ske=2021-12-14T23%3A47%3A36Z&sks=b&skv=2019-07-07&st=2021-12-13T16%3A03%3A12Z&se=2021-12-14T00%3A13%3A12Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://azureml5251422572.blob.core.windows.net/azureml/ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=HoFgI7WSvr9i9vXhur%2FRnn4%2BtivsT1bf4h%2BL%2FpIHr5U%3D&skoid=33ba0eac-bf3e-4596-b8a9-4b07563781ca&sktid=164ae192-78d8-4cdf-97f3-9b8996479a42&skt=2021-12-13T15%3A37%3A36Z&ske=2021-12-14T23%3A47%3A36Z&sks=b&skv=2019-07-07&st=2021-12-13T16%3A03%3A12Z&se=2021-12-14T00%3A13%3A12Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/16172_azureml.log\"]], \"run_duration\": \"0:09:28\", \"run_number\": \"44\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"RMSE\", \"run_id\": \"dimond_experiment_1639396756_a9e45179\", \"categories\": [0], \"series\": [{\"data\": [1586.727294921875]}]}, {\"name\": \"MAPE\", \"run_id\": \"dimond_experiment_1639396756_a9e45179\", \"categories\": [0], \"series\": [{\"data\": [15.646038055419922]}]}], \"run_logs\": \"2021-12-13 13:05:26,212|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\r\\n2021-12-13 13:05:26,216|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: none\\r\\n2021-12-13 13:05:26,480|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\r\\n2021-12-13 13:05:26,481|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\r\\n2021-12-13 13:05:28,824|azureml.core.run|DEBUG|Adding new factory <function PipelineRun._from_dto at 0x000001EDB0430CA0> for run source azureml.PipelineRun\\r\\n2021-12-13 13:05:28,865|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_reused_dto at 0x000001EDB043B790> for run source azureml.ReusedStepRun\\r\\n2021-12-13 13:05:28,911|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_dto at 0x000001EDB043B700> for run source azureml.StepRun\\r\\n2021-12-13 13:05:29,804|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\r\\n2021-12-13 13:05:29,805|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\r\\n2021-12-13 13:05:29,805|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\r\\n2021-12-13 13:05:29,805|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\r\\n2021-12-13 13:05:29,810|azureml.core.run|DEBUG|Adding new factory <function AutoMLRun._from_run_dto at 0x000001EDAE33B0D0> for run source automl\\r\\n2021-12-13 13:05:29,853|azureml.core.run|DEBUG|Adding new factory <function HyperDriveRun._from_run_dto at 0x000001EDAE3E5E50> for run source hyperdrive\\r\\n2021-12-13 13:05:29,926|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x000001EDAF257A60> for run source azureml.scriptrun\\r\\n2021-12-13 13:05:29,945|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\r\\n2021-12-13 13:05:29,945|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\r\\n2021-12-13 13:05:29,947|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\r\\n2021-12-13 13:05:29,947|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\r\\n2021-12-13 13:05:29,950|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\r\\n2021-12-13 13:05:29,950|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\r\\n2021-12-13 13:05:29,956|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\r\\n2021-12-13 13:05:30,079|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\r\\n2021-12-13 13:05:30,080|azureml.core.authentication|DEBUG|Time to expire 1817626.919561 seconds\\r\\n2021-12-13 13:05:30,080|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\r\\n2021-12-13 13:05:30,082|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,087|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,091|azureml.core.authentication|DEBUG|Time to expire 1817626.908566 seconds\\r\\n2021-12-13 13:05:30,092|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\r\\n2021-12-13 13:05:30,095|azureml.core.authentication|DEBUG|Time to expire 1817626.904571 seconds\\r\\n2021-12-13 13:05:30,095|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\r\\n2021-12-13 13:05:30,096|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,097|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,098|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,099|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,107|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,108|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,108|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,109|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,111|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,142|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,143|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,146|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,146|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,158|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,158|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,158|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,160|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,161|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,161|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:30,614|azureml.core._metrics|DEBUG|numpy.float128 is unsupported, expected for windows\\r\\n2021-12-13 13:05:30,862|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\r\\n2021-12-13 13:05:30,862|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\r\\n2021-12-13 13:05:30,902|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\r\\n2021-12-13 13:05:30,903|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\r\\n2021-12-13 13:05:30,911|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\r\\n2021-12-13 13:05:30,911|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\r\\n2021-12-13 13:05:33,637|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\r\\n2021-12-13 13:05:33,640|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': 'afa937ca-63a3-46c2-83ec-cbb6934d65d3', 'azureml.git.repository_uri': 'https://github.com/amine-akrout/diamond-price-prediction.git', 'mlflow.source.git.repoURL': 'https://github.com/amine-akrout/diamond-price-prediction.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': 'e8a632cb9fe5b8164a4a9bb64efe284b2ee98641', 'mlflow.source.git.commit': 'e8a632cb9fe5b8164a4a9bb64efe284b2ee98641', 'azureml.git.dirty': 'False'}\\r\\n2021-12-13 13:05:33,640|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\r\\n2021-12-13 13:05:33,647|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\r\\n2021-12-13 13:05:33,652|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': 'afa937ca-63a3-46c2-83ec-cbb6934d65d3', 'azureml.git.repository_uri': 'https://github.com/amine-akrout/diamond-price-prediction.git', 'mlflow.source.git.repoURL': 'https://github.com/amine-akrout/diamond-price-prediction.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': 'e8a632cb9fe5b8164a4a9bb64efe284b2ee98641', 'mlflow.source.git.commit': 'e8a632cb9fe5b8164a4a9bb64efe284b2ee98641', 'azureml.git.dirty': 'False'}\\r\\n2021-12-13 13:05:33,652|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\r\\n2021-12-13 13:05:33,664|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\r\\n2021-12-13 13:05:33,667|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': 'afa937ca-63a3-46c2-83ec-cbb6934d65d3', 'azureml.git.repository_uri': 'https://github.com/amine-akrout/diamond-price-prediction.git', 'mlflow.source.git.repoURL': 'https://github.com/amine-akrout/diamond-price-prediction.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': 'e8a632cb9fe5b8164a4a9bb64efe284b2ee98641', 'mlflow.source.git.commit': 'e8a632cb9fe5b8164a4a9bb64efe284b2ee98641', 'azureml.git.dirty': 'False'}\\r\\n2021-12-13 13:05:33,667|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\r\\n2021-12-13 13:05:33,672|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\r\\n2021-12-13 13:05:33,672|azureml.WorkerPool|DEBUG|[START]\\r\\n2021-12-13 13:05:33,673|azureml.SendRunKillSignal|DEBUG|[START]\\r\\n2021-12-13 13:05:33,673|azureml.RunStatusContext|DEBUG|[START]\\r\\n2021-12-13 13:05:33,673|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunContextManager.RunStatusContext|DEBUG|[START]\\r\\n2021-12-13 13:05:33,674|azureml.MetricsClient|DEBUG|[START]\\r\\n2021-12-13 13:05:33,674|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient|DEBUG|[START]\\r\\n2021-12-13 13:05:33,674|azureml.ContentUploader|DEBUG|[START]\\r\\n2021-12-13 13:05:33,677|azureml._history.utils.context_managers|DEBUG|starting file watcher\\r\\n2021-12-13 13:05:33,678|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\r\\n2021-12-13 13:05:33,679|azureml.TrackFolders|DEBUG|[START]\\r\\n2021-12-13 13:05:33,680|azureml.WorkingDirectoryCM|DEBUG|[START]\\r\\n2021-12-13 13:05:33,680|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\r\\n2021-12-13 13:05:33,680|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: C:\\\\Users\\\\yomke\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\dimond_experiment_1639396756_a9e45179\\r\\n2021-12-13 13:05:33,681|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\r\\n2021-12-13 13:05:33,681|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as C:\\\\Users\\\\yomke\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\dimond_experiment_1639396756_a9e45179\\r\\n2021-12-13 13:05:33,973|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\r\\n2021-12-13 13:05:33,974|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\r\\n2021-12-13 13:05:36,220|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\r\\n2021-12-13 13:05:38,408|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/logs/azureml/16172_azureml.log path: C:\\\\Users\\\\yomke\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\dimond_experiment_1639396756_a9e45179\\\\logs\\\\azureml\\\\16172_azureml.log\\r\\n2021-12-13 13:05:38,409|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:05:38,412|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:05:38,413|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\r\\n2021-12-13 13:05:46,548|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\r\\n2021-12-13 13:05:46,548|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\r\\n2021-12-13 13:05:46,549|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\r\\n2021-12-13 13:05:46,550|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:46,554|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:46,556|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:46,556|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:46,560|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:46,560|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:46,560|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://francecentral.api.azureml.ms.\\r\\n2021-12-13 13:05:48,431|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:05:48,431|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:05:48,431|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\r\\n2021-12-13 13:05:58,448|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\r\\n2021-12-13 13:05:58,448|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\r\\n2021-12-13 13:06:00,715|azureml.core.authentication|DEBUG|Time to expire 1817596.28509 seconds\\r\\n2021-12-13 13:06:01,113|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\r\\n2021-12-13 13:06:02,635|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/logs/azureml/dataprep/backgroundProcess.log path: C:\\\\Users\\\\yomke\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\dimond_experiment_1639396756_a9e45179\\\\logs\\\\azureml\\\\dataprep\\\\backgroundProcess.log\\r\\n2021-12-13 13:06:04,097|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/logs/azureml/dataprep/backgroundProcess_Telemetry.log path: C:\\\\Users\\\\yomke\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\dimond_experiment_1639396756_a9e45179\\\\logs\\\\azureml\\\\dataprep\\\\backgroundProcess_Telemetry.log\\r\\n2021-12-13 13:06:04,098|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:06:04,098|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:06:04,099|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\r\\n2021-12-13 13:06:04,099|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:06:04,101|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:06:04,101|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 3_result to queue of approximate size: 3\\r\\n2021-12-13 13:06:04,104|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:06:04,108|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:06:04,108|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 4_result to queue of approximate size: 4\\r\\n2021-12-13 13:06:14,122|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:06:14,123|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:06:14,124|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 5_result to queue of approximate size: 5\\r\\n2021-12-13 13:06:14,125|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:06:14,126|azureml._history.utils.context_managers.FileWatcher.UploadQueue.6_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:06:14,126|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 6_result to queue of approximate size: 6\\r\\n2021-12-13 13:06:30,721|azureml.core.authentication|DEBUG|Time to expire 1817566.278803 seconds\\r\\n2021-12-13 13:06:34,169|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:06:34,170|azureml._history.utils.context_managers.FileWatcher.UploadQueue.7_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:06:34,170|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 7_result to queue of approximate size: 7\\r\\n2021-12-13 13:07:00,727|azureml.core.authentication|DEBUG|Time to expire 1817536.272664 seconds\\r\\n2021-12-13 13:07:04,205|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:07:04,205|azureml._history.utils.context_managers.FileWatcher.UploadQueue.8_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:07:04,206|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 8_result to queue of approximate size: 8\\r\\n2021-12-13 13:07:30,737|azureml.core.authentication|DEBUG|Time to expire 1817506.262086 seconds\\r\\n2021-12-13 13:07:34,249|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:07:34,249|azureml._history.utils.context_managers.FileWatcher.UploadQueue.9_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:07:34,250|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 9_result to queue of approximate size: 9\\r\\n2021-12-13 13:08:00,362|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\r\\n2021-12-13 13:08:00,363|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\r\\n2021-12-13 13:08:00,365|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\r\\n2021-12-13 13:08:00,757|azureml.core.authentication|DEBUG|Time to expire 1817476.242499 seconds\\r\\n2021-12-13 13:08:01,378|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\r\\n2021-12-13 13:08:01,378|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\r\\n2021-12-13 13:08:01,382|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 2.\\r\\n2021-12-13 13:08:01,382|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\r\\n2021-12-13 13:08:01,383|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:08:01,385|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\r\\n2021-12-13 13:08:01,386|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 2 values.\\r\\n2021-12-13 13:08:01,389|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\r\\n2021-12-13 13:08:01,389|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:08:01,390|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\r\\n2021-12-13 13:08:01,393|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\r\\n2021-12-13 13:08:01,396|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\r\\n2021-12-13 13:08:01,398|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\r\\n2021-12-13 13:08:01,404|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\r\\n2021-12-13 13:08:01,429|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\r\\n2021-12-13 13:08:01,429|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:01,430|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\r\\n2021-12-13 13:08:01,430|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:01,430|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\r\\n2021-12-13 13:08:01,431|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\r\\n2021-12-13 13:08:03,651|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\r\\n2021-12-13 13:08:04,427|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:08:04,428|azureml._history.utils.context_managers.FileWatcher.UploadQueue.10_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:08:04,428|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 10_result to queue of approximate size: 10\\r\\n2021-12-13 13:08:16,629|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179|INFO|complete is not setting status for submitted runs.\\r\\n2021-12-13 13:08:16,629|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\r\\n2021-12-13 13:08:16,630|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\r\\n2021-12-13 13:08:16,630|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\r\\n2021-12-13 13:08:16,632|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\r\\n2021-12-13 13:08:16,633|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\r\\n2021-12-13 13:08:16,633|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\r\\n2021-12-13 13:08:16,633|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\r\\n2021-12-13 13:08:16,634|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\r\\n2021-12-13 13:08:16,634|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\r\\n2021-12-13 13:08:16,634|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\r\\n2021-12-13 13:08:16,634|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\r\\n2021-12-13 13:08:16,635|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\r\\n2021-12-13 13:08:16,635|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:16,635|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\r\\n2021-12-13 13:08:16,635|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:16,636|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\r\\n2021-12-13 13:08:16,636|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\r\\n2021-12-13 13:08:16,636|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\r\\n2021-12-13 13:08:16,637|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\r\\n2021-12-13 13:08:16,637|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\r\\n2021-12-13 13:08:19,059|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\r\\n2021-12-13 13:08:19,062|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\r\\n2021-12-13 13:08:19,062|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\r\\n2021-12-13 13:08:19,869|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\r\\n2021-12-13 13:08:19,869|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: C:\\\\Users\\\\yomke\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\dimond_experiment_1639396756_a9e45179\\r\\n2021-12-13 13:08:19,870|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from C:\\\\Users\\\\yomke\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\dimond_experiment_1639396756_a9e45179 to C:\\\\Users\\\\yomke\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\dimond_experiment_1639396756_a9e45179\\r\\n2021-12-13 13:08:19,870|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated C:\\\\Users\\\\yomke\\\\AppData\\\\Local\\\\Temp\\\\azureml_runs\\\\dimond_experiment_1639396756_a9e45179\\r\\n2021-12-13 13:08:19,870|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\r\\n2021-12-13 13:08:19,870|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\r\\n2021-12-13 13:08:19,871|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\r\\n2021-12-13 13:08:19,871|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\r\\n2021-12-13 13:08:19,871|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\r\\n2021-12-13 13:08:19,872|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is empty in dir ./outputs\\r\\n2021-12-13 13:08:19,873|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs\\\\model\\\\keras_metadata.pb\\r\\n2021-12-13 13:08:19,873|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs\\\\model\\\\saved_model.pb\\r\\n2021-12-13 13:08:19,873|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is ['./outputs\\\\\\\\model\\\\\\\\keras_metadata.pb', './outputs\\\\\\\\model\\\\\\\\saved_model.pb'] in dir ./outputs\\\\model\\r\\n2021-12-13 13:08:19,874|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Overriding default timeout to 300\\r\\n2021-12-13 13:08:19,874|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Start]\\r\\n2021-12-13 13:08:19,874|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\r\\n2021-12-13 13:08:19,875|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\r\\n2021-12-13 13:08:21,804|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\r\\n2021-12-13 13:08:21,805|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\r\\n2021-12-13 13:08:21,805|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:08:21,806|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\r\\n2021-12-13 13:08:21,806|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\r\\n2021-12-13 13:08:21,808|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\r\\n2021-12-13 13:08:21,809|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.1_perform_upload|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:08:21,809|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 1_perform_upload to queue of approximate size: 1\\r\\n2021-12-13 13:08:21,810|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Stop] - waiting default timeout\\r\\n2021-12-13 13:08:21,810|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\r\\n2021-12-13 13:08:21,810|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 300\\r\\n2021-12-13 13:08:21,810|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0_perform_upload), AsyncTask(1_perform_upload)].\\r\\n2021-12-13 13:08:21,812|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\r\\n2021-12-13 13:08:23,954|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/outputs/model/keras_metadata.pb with size 46592, file size 46592.\\r\\n2021-12-13 13:08:23,991|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/outputs/model/saved_model.pb with size 421508, file size 421508.\\r\\n2021-12-13 13:08:24,100|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:24,101|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\r\\n2021-12-13 13:08:24,101|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:24,101|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.1_perform_upload.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:24,102|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.1_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\r\\n2021-12-13 13:08:24,102|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.1_perform_upload.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:24,103|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\r\\nWaiting on task: 1_perform_upload.\\r\\n2 tasks left. Current duration of flush 0.0010454654693603516 seconds.\\r\\nWaiting on task: 0_perform_upload.\\r\\nWaiting on task: 1_perform_upload.\\r\\n2 tasks left. Current duration of flush 0.26198697090148926 seconds.\\r\\nWaiting on task: 0_perform_upload.\\r\\nWaiting on task: 1_perform_upload.\\r\\n2 tasks left. Current duration of flush 0.51698899269104 seconds.\\r\\nWaiting on task: 0_perform_upload.\\r\\nWaiting on task: 1_perform_upload.\\r\\n2 tasks left. Current duration of flush 0.7719931602478027 seconds.\\r\\nWaiting on task: 0_perform_upload.\\r\\nWaiting on task: 1_perform_upload.\\r\\n2 tasks left. Current duration of flush 1.027001142501831 seconds.\\r\\nWaiting on task: 0_perform_upload.\\r\\nWaiting on task: 1_perform_upload.\\r\\n2 tasks left. Current duration of flush 1.2819843292236328 seconds.\\r\\nWaiting on task: 0_perform_upload.\\r\\nWaiting on task: 1_perform_upload.\\r\\n2 tasks left. Current duration of flush 1.5359971523284912 seconds.\\r\\nWaiting on task: 0_perform_upload.\\r\\nWaiting on task: 1_perform_upload.\\r\\n2 tasks left. Current duration of flush 1.7889971733093262 seconds.\\r\\nWaiting on task: 0_perform_upload.\\r\\nWaiting on task: 1_perform_upload.\\r\\n2 tasks left. Current duration of flush 2.039027690887451 seconds.\\r\\n\\r\\n2021-12-13 13:08:24,103|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\r\\n2021-12-13 13:08:24,104|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is empty in dir ./outputs\\\\model\\\\assets\\r\\n2021-12-13 13:08:24,105|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs\\\\model\\\\variables\\\\variables.data-00000-of-00001\\r\\n2021-12-13 13:08:24,105|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs\\\\model\\\\variables\\\\variables.index\\r\\n2021-12-13 13:08:24,105|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is ['./outputs\\\\\\\\model\\\\\\\\variables\\\\\\\\variables.data-00000-of-00001', './outputs\\\\\\\\model\\\\\\\\variables\\\\\\\\variables.index'] in dir ./outputs\\\\model\\\\variables\\r\\n2021-12-13 13:08:24,106|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Overriding default timeout to 300\\r\\n2021-12-13 13:08:24,106|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Start]\\r\\n2021-12-13 13:08:24,107|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\r\\n2021-12-13 13:08:24,107|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\r\\n2021-12-13 13:08:24,689|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:08:24,690|azureml._history.utils.context_managers.FileWatcher.UploadQueue.11_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:08:24,690|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 11_result to queue of approximate size: 11\\r\\n2021-12-13 13:08:25,735|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\r\\n2021-12-13 13:08:25,736|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\r\\n2021-12-13 13:08:25,736|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:08:25,737|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\r\\n2021-12-13 13:08:25,737|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\r\\n2021-12-13 13:08:25,737|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.1_perform_upload|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:08:25,737|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 1_perform_upload to queue of approximate size: 1\\r\\n2021-12-13 13:08:25,738|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Stop] - waiting default timeout\\r\\n2021-12-13 13:08:25,738|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\r\\n2021-12-13 13:08:25,738|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 300\\r\\n2021-12-13 13:08:25,739|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0_perform_upload), AsyncTask(1_perform_upload)].\\r\\n2021-12-13 13:08:25,740|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\r\\n2021-12-13 13:08:25,741|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\r\\n2021-12-13 13:08:25,980|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/outputs/model/variables/variables.index with size 3654, file size 3654.\\r\\n2021-12-13 13:08:25,999|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.1_perform_upload.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:25,999|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.1_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\r\\n2021-12-13 13:08:26,000|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.1_perform_upload.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,023|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/outputs/model/variables/variables.data-00000-of-00001 with size 210148, file size 210148.\\r\\n2021-12-13 13:08:26,251|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,251|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\r\\n2021-12-13 13:08:26,252|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,252|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\r\\nWaiting on task: 1_perform_upload.\\r\\n2 tasks left. Current duration of flush 0.0009989738464355469 seconds.\\r\\nWaiting on task: 0_perform_upload.\\r\\n1 tasks left. Current duration of flush 0.26229238510131836 seconds.\\r\\n\\r\\n2021-12-13 13:08:26,252|azureml._SubmittedRun#dimond_experiment_1639396756_a9e45179.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,252|azureml.TrackFolders|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,253|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\r\\n2021-12-13 13:08:26,253|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\r\\n2021-12-13 13:08:26,253|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\r\\n2021-12-13 13:08:26,257|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:08:26,257|azureml._history.utils.context_managers.FileWatcher.UploadQueue.12_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:08:26,258|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 12_result to queue of approximate size: 12\\r\\n2021-12-13 13:08:26,258|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\r\\n2021-12-13 13:08:26,259|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,281|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,285|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,289|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,292|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,296|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,300|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,304|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,307|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,311|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,314|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,318|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,321|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,325|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\r\\n2021-12-13 13:08:26,331|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\r\\n2021-12-13 13:08:26,332|azureml._history.utils.context_managers.FileWatcher.UploadQueue.13_result|DEBUG|Using basic handler - no exception handling\\r\\n2021-12-13 13:08:26,332|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 13_result to queue of approximate size: 13\\r\\n2021-12-13 13:08:26,333|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\r\\n2021-12-13 13:08:26,333|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\r\\n2021-12-13 13:08:26,333|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\r\\n2021-12-13 13:08:26,334|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\r\\n2021-12-13 13:08:26,334|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result), AsyncTask(3_result), AsyncTask(4_result), AsyncTask(5_result), AsyncTask(6_result), AsyncTask(7_result), AsyncTask(8_result), AsyncTask(9_result), AsyncTask(10_result), AsyncTask(11_result), AsyncTask(12_result), AsyncTask(13_result)].\\r\\n2021-12-13 13:08:26,335|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,335|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,335|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,336|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,336|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,336|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,336|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,336|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,337|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,337|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,337|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,337|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,338|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,338|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,338|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,339|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,339|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,339|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,339|azureml._history.utils.context_managers.FileWatcher.UploadQueue.6_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.6_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.6_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.7_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.7_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.7_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.8_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.8_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.8_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.9_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.9_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.9_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.10_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.10_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.10_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.11_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.11_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,344|azureml._history.utils.context_managers.FileWatcher.UploadQueue.11_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,344|azureml._history.utils.context_managers.FileWatcher.UploadQueue.12_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,344|azureml._history.utils.context_managers.FileWatcher.UploadQueue.12_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,344|azureml._history.utils.context_managers.FileWatcher.UploadQueue.12_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,597|azureml._history.utils.context_managers.FileWatcher.UploadQueue.13_result.WaitingTask|DEBUG|[START]\\r\\n2021-12-13 13:08:26,597|azureml._history.utils.context_managers.FileWatcher.UploadQueue.13_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\r\\n2021-12-13 13:08:26,598|azureml._history.utils.context_managers.FileWatcher.UploadQueue.13_result.WaitingTask|DEBUG|[STOP]\\r\\n2021-12-13 13:08:26,598|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Waiting on task: 13_result.\\r\\n1 tasks left. Current duration of flush 0.010996341705322266 seconds.\\r\\n\\r\\n2021-12-13 13:08:26,598|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\r\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.36.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'dimond_experiment_1639396756_a9e45179',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-12-13T12:05:21.061357Z',\n",
       " 'endTimeUtc': '2021-12-13T12:08:46.277592Z',\n",
       " 'services': {},\n",
       " 'warnings': [{'message': 'Specifying a version of the certifi python package is not recommended. It receives regular updates with new versions of root certificates and old versions will not be compatible with new python installations.'}],\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': 'afa937ca-63a3-46c2-83ec-cbb6934d65d3',\n",
       "  'azureml.git.repository_uri': 'https://github.com/amine-akrout/diamond-price-prediction.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/amine-akrout/diamond-price-prediction.git',\n",
       "  'azureml.git.branch': 'main',\n",
       "  'mlflow.source.git.branch': 'main',\n",
       "  'azureml.git.commit': 'e8a632cb9fe5b8164a4a9bb64efe284b2ee98641',\n",
       "  'mlflow.source.git.commit': 'e8a632cb9fe5b8164a4a9bb64efe284b2ee98641',\n",
       "  'azureml.git.dirty': 'False'},\n",
       " 'inputDatasets': [{'dataset': {'id': '9213f376-45c3-4237-be26-0f67b6447ef0'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'model.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--input-data', 'DatasetConsumptionConfig:training_data'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'training_data': {'dataLocation': {'dataset': {'id': '9213f376-45c3-4237-be26-0f67b6447ef0',\n",
       "      'name': 'diamond dataset',\n",
       "      'version': '1'},\n",
       "     'dataPath': None,\n",
       "     'uri': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'training_data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False,\n",
       "    'options': None}},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'tf_env',\n",
       "   'version': '2',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge', 'defaults'],\n",
       "     'dependencies': ['backcall=0.2.0',\n",
       "      'backports=1.0',\n",
       "      'backports.functools_lru_cache=1.6.4',\n",
       "      'ca-certificates=2021.10.8',\n",
       "      'certifi=2021.10.8',\n",
       "      'colorama=0.4.4',\n",
       "      'debugpy=1.5.1',\n",
       "      'decorator=5.1.0',\n",
       "      'entrypoints=0.3',\n",
       "      'ipykernel=6.4.1',\n",
       "      'ipython=7.30.1',\n",
       "      'ipython_genutils=0.2.0',\n",
       "      'jedi=0.18.1',\n",
       "      'jupyter_client=7.1.0',\n",
       "      'jupyter_core=4.9.1',\n",
       "      'libsodium=1.0.18',\n",
       "      'matplotlib-inline=0.1.3',\n",
       "      'nest-asyncio=1.5.4',\n",
       "      'openssl=3.0.0',\n",
       "      'parso=0.8.3',\n",
       "      'pickleshare=0.7.5',\n",
       "      'pip=21.3.1',\n",
       "      'prompt-toolkit=3.0.24',\n",
       "      'pygments=2.10.0',\n",
       "      'python=3.8.12',\n",
       "      'python-dateutil=2.8.2',\n",
       "      'python_abi=3.8',\n",
       "      'pywin32=302',\n",
       "      'pyzmq=22.3.0',\n",
       "      'setuptools=59.4.0',\n",
       "      'six=1.16.0',\n",
       "      'sqlite=3.37.0',\n",
       "      'tornado=6.1',\n",
       "      'traitlets=5.1.1',\n",
       "      'ucrt=10.0.20348.0',\n",
       "      'vc=14.2',\n",
       "      'vs2015_runtime=14.29.30037',\n",
       "      'wcwidth=0.2.5',\n",
       "      'wheel=0.37.0',\n",
       "      'zeromq=4.3.4',\n",
       "      {'pip': ['adal==1.2.7',\n",
       "        'applicationinsights==0.11.10',\n",
       "        'azure-common==1.1.27',\n",
       "        'azure-core==1.21.1',\n",
       "        'azure-graphrbac==0.61.1',\n",
       "        'azure-identity==1.7.0',\n",
       "        'azure-mgmt-authorization==0.61.0',\n",
       "        'azure-mgmt-containerregistry==8.2.0',\n",
       "        'azure-mgmt-core==1.3.0',\n",
       "        'azure-mgmt-keyvault==9.3.0',\n",
       "        'azure-mgmt-resource==13.0.0',\n",
       "        'azure-mgmt-storage==11.2.0',\n",
       "        'azureml-core==1.36.0.post2',\n",
       "        'azureml-dataprep==2.24.4',\n",
       "        'azureml-dataprep-native==38.0.0',\n",
       "        'azureml-dataprep-rslex==2.0.3',\n",
       "        'azureml-dataset-runtime==1.36.0',\n",
       "        'azureml-defaults==1.36.0',\n",
       "        'azureml-inference-server-http==0.4.2',\n",
       "        'backports-tempfile==1.0',\n",
       "        'backports-weakref==1.0.post1',\n",
       "        'cffi==1.15.0',\n",
       "        'charset-normalizer==2.0.9',\n",
       "        'click==8.0.3',\n",
       "        'cloudpickle==1.6.0',\n",
       "        'configparser==3.7.4',\n",
       "        'contextlib2==21.6.0',\n",
       "        'cryptography==3.4.8',\n",
       "        'distro==1.6.0',\n",
       "        'docker==5.0.3',\n",
       "        'dotnetcore2==2.1.22',\n",
       "        'flask==1.0.3',\n",
       "        'fusepy==3.0.1',\n",
       "        'google-auth==2.3.3',\n",
       "        'grpcio==1.42.0',\n",
       "        'idna==3.3',\n",
       "        'inference-schema==1.3.0',\n",
       "        'isodate==0.6.0',\n",
       "        'itsdangerous==2.0.1',\n",
       "        'jeepney==0.7.1',\n",
       "        'jinja2==3.0.3',\n",
       "        'jmespath==0.10.0',\n",
       "        'json-logging-py==0.2',\n",
       "        'jsonpickle==2.0.0',\n",
       "        'keras==2.7.0',\n",
       "        'libclang==12.0.0',\n",
       "        'markupsafe==2.0.1',\n",
       "        'msal==1.16.0',\n",
       "        'msal-extensions==0.3.1',\n",
       "        'msrest==0.6.21',\n",
       "        'msrestazure==0.6.4',\n",
       "        'ndg-httpsclient==0.5.1',\n",
       "        'numpy==1.21.4',\n",
       "        'pandas==1.3.5',\n",
       "        'pathspec==0.9.0',\n",
       "        'portalocker==2.3.2',\n",
       "        'psutil==5.8.0',\n",
       "        'pyarrow==3.0.0',\n",
       "        'pycparser==2.21',\n",
       "        'pyjwt==2.3.0',\n",
       "        'pyopenssl==20.0.1',\n",
       "        'pytz==2021.3',\n",
       "        'requests==2.26.0',\n",
       "        'secretstorage==3.3.1',\n",
       "        'tensorboard==2.7.0',\n",
       "        'tensorboard-data-server==0.6.1',\n",
       "        'tensorflow==2.7.0',\n",
       "        'tensorflow-estimator==2.7.0',\n",
       "        'tensorflow-io-gcs-filesystem==0.22.0',\n",
       "        'urllib3==1.26.7',\n",
       "        'waitress==2.0.0',\n",
       "        'websocket-client==1.2.3']}],\n",
       "     'name': 'azureml_1336f703c08b034e282ff5e13e8dc294'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211029.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://azureml5251422572.blob.core.windows.net/azureml/ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=7b0GXlhGLcDtbJTAV4S9lGhQwrB7whrPFcTMiVnGGn0%3D&skoid=33ba0eac-bf3e-4596-b8a9-4b07563781ca&sktid=164ae192-78d8-4cdf-97f3-9b8996479a42&skt=2021-12-13T11%3A58%3A20Z&ske=2021-12-14T20%3A08%3A20Z&sks=b&skv=2019-07-07&st=2021-12-13T11%3A58%3A46Z&se=2021-12-13T20%3A08%3A46Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://azureml5251422572.blob.core.windows.net/azureml/ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=PfSiMfQwRequrPKXEnstU6fTsg4s1gyZArgdPfx0Bcw%3D&skoid=33ba0eac-bf3e-4596-b8a9-4b07563781ca&sktid=164ae192-78d8-4cdf-97f3-9b8996479a42&skt=2021-12-13T11%3A58%3A20Z&ske=2021-12-14T20%3A08%3A20Z&sks=b&skv=2019-07-07&st=2021-12-13T11%3A58%3A46Z&se=2021-12-13T20%3A08%3A46Z&sp=r',\n",
       "  'logs/azureml/16172_azureml.log': 'https://azureml5251422572.blob.core.windows.net/azureml/ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/logs/azureml/16172_azureml.log?sv=2019-07-07&sr=b&sig=dvFskTLrentBExxb%2F4ZgifueG8K3i7GPrUFyAiMblNo%3D&skoid=33ba0eac-bf3e-4596-b8a9-4b07563781ca&sktid=164ae192-78d8-4cdf-97f3-9b8996479a42&skt=2021-12-12T23%3A50%3A25Z&ske=2021-12-14T08%3A00%3A25Z&sks=b&skv=2019-07-07&st=2021-12-13T11%3A56%3A16Z&se=2021-12-13T20%3A06%3A16Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://azureml5251422572.blob.core.windows.net/azureml/ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=Vx7RMwzk2hUZzw5FfiDoAZHpgjwAvoyyApFUqhCaC7Q%3D&skoid=33ba0eac-bf3e-4596-b8a9-4b07563781ca&sktid=164ae192-78d8-4cdf-97f3-9b8996479a42&skt=2021-12-12T23%3A50%3A25Z&ske=2021-12-14T08%3A00%3A25Z&sks=b&skv=2019-07-07&st=2021-12-13T11%3A56%3A16Z&se=2021-12-13T20%3A06%3A16Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://azureml5251422572.blob.core.windows.net/azureml/ExperimentRun/dcid.dimond_experiment_1639396756_a9e45179/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=wmm92ihjFySvFK7aQ%2F0tlsyYlFtNBnFpKE7GiciNcLc%3D&skoid=33ba0eac-bf3e-4596-b8a9-4b07563781ca&sktid=164ae192-78d8-4cdf-97f3-9b8996479a42&skt=2021-12-12T23%3A50%3A25Z&ske=2021-12-14T08%3A00%3A25Z&sks=b&skv=2019-07-07&st=2021-12-13T11%3A56%3A16Z&se=2021-12-13T20%3A06%3A16Z&sp=r'},\n",
       " 'submittedBy': 'akrout.med.amine akrout.med.amine'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Get the training dataset\n",
    "diamond_ds = ws.datasets.get(\"diamond dataset\")\n",
    "\n",
    "src = ScriptRunConfig(source_directory='./training',\n",
    "                      script='model.py',\n",
    "                      compute_target='local',\n",
    "                      arguments = ['--input-data', diamond_ds.as_named_input('training_data')],\n",
    "                      environment=tf_env)\n",
    "\n",
    "run = experiment.submit(config=src)\n",
    "\n",
    "# Show the running experiment run in the notebook widget\n",
    "RunDetails(run).show()\n",
    "# Block until the experiment run has completed\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 1586.727294921875\n",
      "MAPE 15.646038055419922\n",
      "\n",
      "\n",
      "azureml-logs/60_control_log.txt\n",
      "azureml-logs/70_driver_log.txt\n",
      "logs/azureml/16172_azureml.log\n",
      "logs/azureml/dataprep/backgroundProcess.log\n",
      "logs/azureml/dataprep/backgroundProcess_Telemetry.log\n",
      "outputs/model/keras_metadata.pb\n",
      "outputs/model/saved_model.pb\n",
      "outputs/model/variables/variables.data-00000-of-00001\n",
      "outputs/model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "# Get logged metrics and files\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  diamond_model\n",
      "Model id:  diamond_model:6\n",
      "Model version:  6\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "\n",
    "model = run.register_model(model_path='./outputs/model/', \n",
    "                        model_name='diamond_model',\n",
    "                        tags={'Training context':'Script'},\n",
    "                        properties={'RMSE': run.get_metrics()['RMSE'], 'MAPE': run.get_metrics()['MAPE']})\n",
    "\n",
    "print(\"Model name: \", model.name)\n",
    "print(\"Model id: \", model.id)\n",
    "print(\"Model version: \", model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'azureml-models\\\\diamond_model\\\\6\\\\model'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   from azureml.core.model import Model\n",
    "   model_path = Model.get_model_path('diamond_model', _workspace = ws)\n",
    "   print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated price : 431.65622 +/- 9%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "reloaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Perform inference\n",
    "raw_data = {\n",
    "    'carat': 0.23,\n",
    "    'cut': 'Ideal',\n",
    "    'color': 'E',\n",
    "    'clarity': 'SI2',\n",
    "    'depth': 61.5,\n",
    "    'table': 55.0,\n",
    "    'x': 3.95,\n",
    "    'y': 3.98,\n",
    "    'z': 2.43,\n",
    "}\n",
    "volume = raw_data['x']*raw_data['y']*raw_data['z']\n",
    "raw_data['volume'] =  volume\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in raw_data.items()}\n",
    "predictions = reloaded_model.predict(input_dict)\n",
    "predicted = predictions[0]\n",
    "\n",
    "print(\"estimated price :\", predicted[0], \"+/- 9%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create deployment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './deployment'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create scoring script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from azureml.core.model import Model\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path('diamond_model')\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "\n",
    "def run(data):\n",
    "    test = json.loads(data)\n",
    "    print(f\"received data {test}\")\n",
    "    input_dict = {name: tf.convert_to_tensor([value]) for name, value in test.items()}\n",
    "    predictions = model.predict(input_dict)\n",
    "    predicted = predictions[0]\n",
    "    result = str(round(predicted[0],2))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure inference environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and register an inference environment from yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_env = Environment.from_conda_specification(name = \"inf_env\",\n",
    "                                             file_path = \"./inf_env.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "inference_config = InferenceConfig(\n",
    "    entry_script='./score.py', \n",
    "    environment=inf_env\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ACI configuration\n",
    "Create a deployment configuration file and specify the number of CPUs and gigabyte of RAM needed for your ACI container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=1, \n",
    "    memory_gb=1, \n",
    "    tags={\"data\": \"diamond\",  \"method\" : \"tensorflow\"}, \n",
    "    description='Predict diamond price with tensorflow'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy in ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-12-13 17:10:13+01:00 Creating Container Registry if not exists.\n",
      "2021-12-13 17:10:13+01:00 Registering the environment.\n",
      "2021-12-13 17:10:15+01:00 Use the existing image.\n",
      "2021-12-13 17:10:15+01:00 Generating deployment configuration.\n",
      "2021-12-13 17:10:16+01:00 Submitting deployment to compute.\n",
      "2021-12-13 17:10:19+01:00 Checking the status of deployment diamond-price-aci-svc..\n",
      "2021-12-13 17:12:00+01:00 Checking the status of inference endpoint diamond-price-aci-svc.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aci_service_name = 'diamond-price-aci-svc'\n",
    "aci_service = Model.deploy(workspace=ws,\n",
    "                           name=aci_service_name,\n",
    "                           models=[model],\n",
    "                           inference_config=inference_config,\n",
    "                           deployment_config=aci_config,\n",
    "                           overwrite=True)\n",
    "aci_service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring web service's logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aci_service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring web service's HTTP endpoint, which accepts REST client calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://affdaeb4-9abd-473d-a1c2-e35c67dd4b0f.francecentral.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "print(aci_service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://affdaeb4-9abd-473d-a1c2-e35c67dd4b0f.francecentral.azurecontainer.io/swagger.json\n"
     ]
    }
   ],
   "source": [
    "print(aci_service.swagger_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test deployed service\n",
    "Now, we can test the deployed model with a sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST to url http://affdaeb4-9abd-473d-a1c2-e35c67dd4b0f.francecentral.azurecontainer.io/score\n",
      "input data: {\"carat\": 0.23, \"cut\": \"Ideal\", \"color\": \"E\", \"clarity\": \"SI2\", \"depth\": 61.5, \"table\": 55.0, \"x\": 3.95, \"y\": 3.98, \"z\": 2.43, \"volume\": 38.20203}\n",
      "response  431.66\n",
      "response  \"431.66\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# send a random row from the test set to score\n",
    "\n",
    "data = {\n",
    "    'carat': 0.23,\n",
    "    'cut': 'Ideal',\n",
    "    'color': 'E',\n",
    "    'clarity': 'SI2',\n",
    "    'depth': 61.5,\n",
    "    'table': 55.0,\n",
    "    'x': 3.95,\n",
    "    'y': 3.98,\n",
    "    'z': 2.43,\n",
    "}\n",
    "volume = data['x']*data['y']*data['z']\n",
    "data['volume'] =  volume\n",
    "# input_data = bytes(raw_data, encoding='utf8')\n",
    "data = json.dumps(data)\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "response  = requests.post(aci_service.scoring_uri, data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", aci_service.scoring_uri)\n",
    "print(\"input data:\", data)\n",
    "print(\"response \", response.json())\n",
    "print(\"response \", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de3cac477f00c3497522b4ecacc7d3fdccddad8d321013eb109afea97a01c953"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
